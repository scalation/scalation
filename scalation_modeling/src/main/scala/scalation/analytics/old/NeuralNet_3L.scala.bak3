
//::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** @author  John Miller
 *  @version 1.4
 *  @date    Fri Mar 16 15:13:38 EDT 2018
 *  @see     LICENSE (MIT style license file).
 *
 *  @see     hebb.mit.edu/courses/9.641/2002/lectures/lecture03.pdf
 */

package scalation.analytics

import scalation.linalgebra.{MatriD, MatrixD, VectoD, VectorD}
import scalation.linalgebra.MatrixD.outer
import scalation.math.double_exp
import scalation.calculus.Differential.{FunctionM_2M, FunctionV_2V}
import scalation.random.RandomMatD
import scalation.util.{banner, Error}

import ActivationFun._

//::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `NeuralNet_3L` class supports multi-output, 2-layer (input and output)
 *  Neural-Networks.  Although useful for both classification and prediction,
 *  this class is used for prediction.  Given several input vectors and output
 *  vectors (training data), fit the weights/parameters 'bb' connecting the layers,
 *  so that for a new input vector 'z', the net can predict the output value, i.e.,
 *  <p>
 *      yp_j = f (bb dot z)
 *  <p>
 *  where 'f' is the activation function and the parameter matrix 'bb' gives the
 *  weights between input and output layers.
 *  Note, 'b0' is treated as the bias, so 'x0' must be 1.0.
 *  @param x     the input matrix (training data consisting of m input vectors)
 *  @param y     the output vector (training data consisting of m output values)
 *  @param eta   the learning/convergence rate (typically less than 1.0)
 *  @param fa    the activation function (mapping scalar => scalar)
 *  @param faV   the vector activation function (mapping vector => vector)
 *  @param faD  the derivative of the vector activation function 
 */
class NeuralNet_3L (x: MatriD, y: MatriD, nz: Int, private var eta: Double = 1.0,
                    faV:  FunctionV_2V = sigmoidV _,
                    faM:  FunctionM_2M = sigmoidM _,
                    faDM: FunctionM_2M = sigmoidDM _)
      extends Error
{
    private val DEBUG    = true                                    // debug flag
    private val MAX_ITER = 100                                     // maximum number of iterations
    private val EPSILON  = 1E-9                                    // number close to zero
    private val m        = x.dim1                                  // number of data points (input vectors)
    private val nx       = x.dim2                                  // dimensionality of the input
    private val ny       = y.dim2                                  // dimensionality of the output
    private val _1       = VectorD.one (m)                         // vector of all ones

    private var aa: MatriD = null                                  // weight parameters (in to hid) - new MatrixD (nx, nz)
    private var bb: MatriD = null                                  // weight parameters (hid to out) - new MatrixD (nz, ny)

    private val fitA = Array.ofDim [Fit] (ny)
    for (k <- fitA.indices) fitA(k) = new Fit (y.col(k), nx, (nx-1, m - nx))

    if (y.dim1 != m) flaw ("constructor", "row dimensions of x and y are incompatible")

    println (s"Create a NeuralNet_3L with $nx input, $nz hidden and $ny output nodes")

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Return the weight matrices 'aa' and 'bb'.
     */
    def weights: (MatriD, MatriD) = (aa, bb)

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Set the initial weight matrices 'aa' and 'bb' manually before training.
     *  @param w0a  the initial weights for aa
     *  @param w0b  the initial weights for bb
     */
    def setWeights (w0a: MatriD, w0b: MatriD) { aa = w0a; bb  = w0b }

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Set the initial weight matrix 'bb' with values in (0, 1) before training.
     *  @param stream  the random number stream to use
     */
    def setWeights (stream: Int = 0)
    {
        val rmg1 = new RandomMatD (nx, nz, 1.0, stream = stream)    // change stream to get different random numbers
        aa       = rmg1.gen
        val rmg2 = new RandomMatD (nz, ny, 1.0, stream = stream)    // change stream to get different random numbers
        bb       = rmg2.gen
        if (DEBUG) println (s"setWeights: aa = $aa \n bb = $bb")
    } // setWeights

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Reset the learning rate 'eta'.
     *  @param eta  the learning rate
     */
    def reset (eta_ : Double) { eta = 0.0001 } // eta_ }

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Given training data 'x' and 'yy', fit the parameter/weight matrix 'bb'.
     *  @param yy  the output matrix
     */
    def train (yy: MatriD = y): NeuralNet_3L =
    {
        if (bb == null || aa == null) setWeights ()                // initialize parameters/weights
        minimizeError ()                                           // adjust weights aa and bb to minimize sse
        if (DEBUG) println (s"train: aa = $aa \n bb = $bb")
        this
    } // train

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Minimize the error in the prediction by adjusting the weight vector 'b'.
     *  The error 'e' is simply the difference between the target value 'yy' and the
     *  predicted value 'yp'.  Minimize the dot product of error with itself using
     *  gradient-descent.  The gradient is '-x.t * (e * yp * (_1 - yp))', so move in
     *  the opposite direction of the gradient.
     */
    private def minimizeError ()
    {
        println (s"before (0) bb = $bb")
        println (s"before (0) aa = $aa")
        val nBatches = 5
        for (epoch <- 0 until MAX_ITER) {                             // it-th learning phase

            val bSize = m / nBatches
            for (batch <- 0 until nBatches) {
                val xb = x.slice (batch * bSize, (batch + 1) * bSize)
                val yb = y.slice (batch * bSize, (batch + 1) * bSize)
                var sse0 = Double.MaxValue
                var sse  = 0.0

                    println (s"xb is ${xb.dim1} by ${xb.dim2}")
                    println (s"aa is ${aa.dim1} by ${aa.dim2}")
                val x_aa = xb * aa
                val z  = faM (x_aa)
                    println (s"z is ${z.dim1} by ${z.dim2}")
                    println (s"bb is ${bb.dim1} by ${bb.dim2}")
 //             val yp = (z * bb)
                val yp = faM (z * bb)
                    println (s"yp is ${yp.dim1} by ${yp.dim2}")
                val e  = yb - yp
                    println (s"e is ${e.dim1} by ${e.dim2}")
                    println (s"e = $e")
                val dy = htimes (faDM (z * bb), e) * -1.0
                    println (s"dy is ${dy.dim1} by ${dy.dim2}")
                val bb_dy = (dy * bb.t)
                    println (s"bb_dy is ${bb_dy.dim1} by ${bb_dy.dim2}")
                    println (s"x_aa is ${faDM (x_aa).mean.dim}") // by ${faDM (x_aa).mean.dim2}")
//              val dz = bb_dy
                val dz = htimes (faDM (x_aa), bb_dy)
                    println (s"dz is ${dz.dim1} by ${dz.dim2}")

                for (k <- bb.range2) bb.setCol (k, bb.col (k) - z.t * dy.col(k) * eta)
//              bb -= z.t * dy * eta
//              bb -= z.t * (dy / m) * eta
//              bb -= outer (z.mean, dy.mean) * eta
                    println (s"after ($epoch, $batch) bb = $bb")
                for (k <- aa.range2) aa.setCol (k, aa.col(k) - xb.t * dz.col(k) * eta)
//              aa -= xb.t * dz * eta
//              aa -= xb.t * (dz / m) * eta
//              aa -= outer (x.mean, dz.mean) * eta
                    println (s"after ($epoch, $batch) aa = $aa")

                sse = htimes (e, e).sum

                if (DEBUG) println (s"weights for $epoch th epoch: \n aa = $aa \n bb = $bb \n sse = $sse")
                if (sse0 - sse < EPSILON) return                       // return when sse difference is small enough
                sse0 = sse                                             // save prior sse
            } // for
        } // for

    } // minimizeError

    def htimes (a: MatriD, b: MatriD): MatriD = MatrixD (for (i <- a.range1) yield a(i) * b(i), false)

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Given training data 'x' and 'yy', fit the parameter/weight matrix 'bb'.
     */
    def eval_3L ()
    {
        val yp = predict (x)                                       // predict output/responses
        val e  = y - yp                                            // error matrix
        for (k <- e.range2) fitA(k).diagnose (e.col(k))            // compute diagonostics, per column
    } // eval

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Show 'fitMap' for each y-column.
     */
    def fitMap_3L ()
    {
        var sst, sse = 0.0
        for (k <- fitA.indices) {
            val fit_k = fitA(k).fitMap
            println (s"For column $k: fitMap = \n $fit_k")
            sst += fit_k ("sst").toDouble
            sse += fit_k ("sse").toDouble
        } // for
        val rSq = (sst - sse) / sst
        println (s"overall: rSq = $rSq, sst = $sst, sse = $sse")    
    } // fitMap_3L

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Given a new input vector 'v', predict the output/response value 'f(v)'.
     *  @param v  the new input vector
     */
    def predict (v: VectorD): VectoD = faV (bb * faV (aa * v))

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /*  Given a new input matrix 'x', predict the output/response value 'f(x)'.
     *  @param x  the new input matrix
     */
    def predict (x: MatriD): MatriD = faM (faM (x * aa) * bb)

} // NeuralNet_3L class


//::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `NeuralNet_3LTest` object is used to test the `NeuralNet_3L` class.  For this
 *  test, the initial weights are used for used for prediction.
 *  > runMain scalation.analytics.NeuralNet_3LTest
 */
object NeuralNet_3LTest extends App
{
    val x   = new MatrixD (1, 3)                     // training data - input vectors (not used)
    val y   = new MatrixD (1, 2)                     // training data - output vectors (not used)
    val ann = new NeuralNet_3L (x, y, 3)             // create a NeuralNet_3L

    val bb = new MatrixD ((3, 2), 0.0, 0.3,          // weight matrix bb (input to output layer)
                                  0.5, 0.4,
                                  0.5, 0.4)
    ann.setWeights (null, bb)                        // set initial weights

    val z  = VectorD (1.0, 1.0, 1.0)                 // new input vector z
    val yp = ann.predict (z)                         // predicted output values
    println (s"input vector: z  = $z")
    println (s"output value: yp = $yp")

} // NeuralNet_3LTest object


//::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `NeuralNet_3LTest2` object is used to test the `NeuralNet_3L` class.  For this
 *  test, training data is used to fit the weights before using them for prediction.
 *  @see www4.rgu.ac.uk/files/chapter3%20-%20bp.pdf
 *  > runMain scalation.analytics.NeuralNet_3LTest2
 */
object NeuralNet_3LTest2 extends App
{
    val s = 0                                         // random number stream to use
    val x = new MatrixD ((3, 3), 1.0, 0.35, 0.9,      // training data - input matrix (m vectors)
                                 1.0, 0.20, 0.7,
                                 1.0, 0.40, 0.95)
    val y = new MatrixD ((3, 2), 0.5, 0.4,            // training data - output matrix (m vectors)
                                 0.3, 0.3,
                                 0.6, 0.5)

    println ("input  matrix x = " + x)
    println ("output matrix y = " + y)

    val nn = new NeuralNet_3L (x, y, 3)                // create a NeuralNet_3L

    banner ("NeuralNet_3LTest2: Set the parameter matrix bb manually")

    val bb = new MatrixD ((3, 2), 0.0, 0.2,           // set weight matrix bb manually
                                  0.5, 0.4,
                                  0.5, 0.4)
    nn.setWeights (null, bb)
    println ("bb     = " + nn.weights)
    nn.eval_3L ()
    nn.fitMap_3L ()

    //var yp = nn.predict (x)                           // predicted output value
    println ("target output:    y   = " + y)
    //println ("predicted output: yp  = " + yp)

    banner ("NeuralNet_3LTest2: Set the parameter matrix bb randomly")

    nn.setWeights (s)                                 // set weights randomly
    println ("bb     = " + nn.weights)
    nn.eval_3L ()
    nn.fitMap_3L ()

    //yp = nn.predict (x)                               // predicted output values
    println ("target output:    y   = " + y)
    //println ("predicted output: yp  = " + yp)

    for (eta <- 0.5 to 10.0 by 0.5) {
        banner (s"NeuralNet_3LTest2: Fit the parameter matrix bb using optimization with learning rate $eta")

        nn.reset (eta)
        nn.train ().eval_3L ()                           // fit the weights using training data
        println ("bb     = " + nn.weights)
        nn.fitMap_3L ()

        //yp = nn.predict (x)                           // predicted output values
        println ("target output:    y   = " + y)
        //println ("predicted output: yp  = " + yp)
        println ("yp = " + nn.predict (x(0)))                        // predicted output values for row 0
    } // for

    banner ("NeuralNet_3LTest2: Compare with Linear Regression - first column of y")

    val y0  = y.col(0)                                // use first column of matrix y
    val rg0 = new Regression (x, y0)                  // create a Regression model
    rg0.train ().eval ()
    println ("b      = " + rg0.coefficient)
    println ("fitMap = " +  rg0.fitMap)

    val y0p = rg0.predict (x)                         // predicted output value
    println ("target output:    y0  = " + y0)
    println ("predicted output: y0p = " + y0p)

    banner ("NeuralNet_3LTest2: Compare with Linear Regression - second column of y")

    val y1 = y.col(1)                                 // use second column of matrix y
    val rg1 = new Regression (x, y1)                  // create a Regression model
    rg1.train ().eval ()
    println ("b      = " + rg1.coefficient)
    println ("fitMap = " + rg1.fitMap)

    val y1p = rg1.predict (x)                         // predicted output value
    println ("target output:    y1  = " + y1)
    println ("predicted output: y1p = " + y1p)

} // NeuralNet_3LTest2 object

